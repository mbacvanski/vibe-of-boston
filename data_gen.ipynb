{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21RGJj1IZ-4g"
   },
   "source": [
    "# Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "h6kf1rCRR2xK",
    "outputId": "9e55e8d0-603c-469d-d251-68224db07ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len total = 12480\n",
      "9684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        99.0\n",
       "1        95.0\n",
       "2        96.0\n",
       "3        93.0\n",
       "4        95.0\n",
       "        ...  \n",
       "2552     96.0\n",
       "2554     99.0\n",
       "2555     99.0\n",
       "2556    100.0\n",
       "2557     87.0\n",
       "Name: review_scores_rating, Length: 9684, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_2020_03 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2020-03-16/data/listings.csv.gz', compression='gzip')\n",
    "df_2019_18 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2019-10-18/data/listings.csv.gz', compression='gzip')\n",
    "df_2018_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2018-10-11/data/listings.csv.gz', compression='gzip')\n",
    "df_2017_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2017-10-06/data/listings.csv.gz', compression='gzip')\n",
    "df_2016_09 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2016-09-07/data/listings.csv.gz', compression='gzip')\n",
    "df_2015_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2015-10-03/data/listings.csv.gz', compression='gzip')\n",
    "\n",
    "df_original_listings = pd.concat([df_2020_03, df_2019_18, df_2018_10, df_2017_10, df_2016_09, df_2015_10]).drop_duplicates('id')\n",
    "print('Len total =', len(df_original_listings))\n",
    "\n",
    "df_listings = df_original_listings\n",
    "df_listings = df_listings.replace('nan', '', regex=True)\n",
    "df_listings['summary'] = df_listings['summary'].astype(str)\n",
    "df_listings['space'] = df_listings['space'].astype(str)\n",
    "df_listings['description'] = df_listings['description'].astype(str)\n",
    "df_listings['neighborhood_overview'] = df_listings['neighborhood_overview'].astype(str)\n",
    "df_listings['host_neighbourhood'] = df_listings['host_neighbourhood'].astype(str)\n",
    "df_listings['neighbourhood_cleansed'] = df_listings['neighbourhood_cleansed'].astype(str)\n",
    "df_listings['notes'] = df_listings['notes'].astype(str)\n",
    "df_listings['review_scores_rating'] = df_listings['review_scores_rating'].astype(float)\n",
    "df_listings = df_listings[df_listings['review_scores_rating'].notna()]\n",
    "print(len(df_listings))\n",
    "df_listings['review_scores_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "H5ZijdxcR_fL",
    "outputId": "0f520d45-efa7-40b8-df7b-bee64d1776cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Listings in north end: 347\n",
      "North end is: Counter({'italian': 184, 'historic': 120, 'good': 90, 'old': 75, 'true': 53, 'entire': 45, 'great': 42, 'narrow': 41, 'fine': 31, 'famous': 29, 'amazing': 27, 'residential': 26, 'american': 26, 'public': 25, 'close': 23, 'european': 19, 'easy': 19, 'short': 18, 'rich': 16, 'fresh': 16, 'accessible': 16, 'authentic': 15, 'beautiful': 15, 'yummy': 14, 'friendly': 13, 'safe': 13, 'perfect': 13, 'favorite': 13, 'notable': 13, 'local': 12, 'delicious': 12, 'vibrant': 12, 'little': 9, 'homemade': 9, 'baked': 9, 'incredible': 9, 'convenient': 9, 'countless': 9, 'square': 8, 'historical': 8, 'young': 8, 'wonderful': 7, 'quiet': 7, 'right': 7, 'lively': 7, 'unbeatable': 7, 'charming': 7, 'unique': 6, 'cozy': 6, 'new': 6, 'sure': 6, 'popular': 6, 'small': 6, 'brief': 6, 'bountiful': 6, 'breathtaking': 6, 'plenty': 6, 'colonial': 6, 'central': 5, 'colorful': 5, 'green': 5, 'walkable': 5, 'main': 5, 'endless': 4, 'ideal': 4, 'modern': 4, 'quaint': 4, 'key': 4, 'beloved': 4, 'nice': 4, 'fun': 4, 'major': 4, 'open': 4, 'early': 4, 'busy': 3, 'outdoor': 3, 'prime': 3, 'detailed': 3, 'overall': 3, 'quick': 3, 'sized': 3, 'culinary': 3, 'a.k.a': 3, 'hungry': 3, 'tiny': 3, 'entertaining': 3, 'north': 3, 'large': 3, 'hot': 3, 'plush': 2, 'distinct': 2, 'apt': 2, 'big': 2, 'quirky': 2, 'able': 2, 'significant': 2, 'direct': 2, 'orange': 2, 'renowned': 2, 'bustling': 2, 'alive': 2, 'striking': 2, 'energetic': 2, 'unmatched': 2, 'humble': 2, 'red': 2, 'delectable': 2, 'high': 2, 'free': 2, 'picturesque': 2, 'long': 2, 'veggie': 2, 'personal': 2, 'flat': 2, 'cherished': 2, 'nearby': 2, 'british': 2, '19th': 2, 'fantastic': 2, 'gorgeous': 2, 'romantic': 2, 'warm': 2, '17th': 1, '18th': 1, 'late': 1, 'international': 1, 'southern': 1, 'lite': 1, 'available': 1, 'cute': 1, 'live': 1, 'pink': 1, 'medical': 1, 'premier': 1, 'indelible': 1, 'particular': 1, 'private': 1, 'hidden': 1, 'cheery': 1, 'plentiful': 1, 'doorstep!.': 1, 'straight': 1, 'happy': 1, 'numerous': 1, 'recent': 1, 'trendy': 1, 'intimate': 1, 'less': 1, 'ficial': 1, 'reasonable': 1, 'exposed': 1, 'wooden': 1, 'comfortable': 1, 'monthly': 1, 'ample': 1, 'contemporary': 1, 'timey': 1, 'electric': 1, 'comparable': 1, 'abundant': 1, 'tasty': 1, 'permanent': 1, 'different': 1, 'jewish': 1, 'pasty': 1, 'furnished': 1, 'distinguished': 1, 'laundry': 1, 'lantern': 1, 'infamous': 1, 'touristy': 1, 'organic': 1, 'urban': 1, 'downtown': 1, 'multiple': 1, 'touristic': 1, 'typical': 1, 'effortless': 1, 'mexican': 1, 'food-': 1, 'cobble': 1, 'hard': 1, 'complete': 1, 'memorable': 1, 'eccentric': 1, 'boisterous': 1, 'quieter': 1, 'functional': 1, 'oversized': 1, 'excellent': 1, 'loud': 1, 'iconic': 1, 'tall': 1, 'mere': 1, 'secured': 1, 'prestigious': 1, 'gay': 1, 'chic': 1, 'interested': 1, 'interesting': 1, 'waterfront': 1, 'prepared': 1, '-christoph': 1, '-theater': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "# Download the natural language dataset for english, if this is the first run\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "# Load spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Add in common words that occurr in all listings, that really don't mean anything useful here\n",
    "nlp.Defaults.stop_words |= {'many', 'great', 'nearby', 'short', 'major', 'north', 'south', 'east', 'west', 'easy', 'true', 'local', 'public', 'mi', 'several', 'such', 'main', 'other'}\n",
    "\n",
    "print('great' in nlp.Defaults.stop_words)\n",
    "\n",
    "# Creates a Counter of adjectives used in the \"neighborhood overview\" field of all listings\n",
    "# within the neighborhood name provided. \n",
    "def get_neighborhood_adjectives(name):\n",
    "  \n",
    "  # List of the \"neighborhood_overview\" field for all listings for this neighborhood\n",
    "  overviews = df_listings.loc[df_listings['neighbourhood_cleansed'] == name]['neighborhood_overview']\n",
    "  \n",
    "  list_overviews = '  '.join([overview for overview in overviews])\n",
    "    \n",
    "  # Combine all overviews into one, and load it into spacy\n",
    "  text = nlp(list_overviews)\n",
    "  \n",
    "  # Get the adjectives\n",
    "  adjectives = [token.lemma_ for token in text if token.pos_ == \"ADJ\" and not token.is_stop]\n",
    "  \n",
    "  # Count the adjectives\n",
    "  counter = Counter(adjectives)\n",
    "  \n",
    "  # Remove pronoun forms\n",
    "  counter.pop('-PRON-', None)\n",
    "  \n",
    "  return (len(overviews), counter)\n",
    "\n",
    "  \n",
    "north_end = get_neighborhood_adjectives('North End')\n",
    "print('Listings in north end:', north_end[0])\n",
    "print('North end is:', north_end[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5pEcpPaSA73"
   },
   "outputs": [],
   "source": [
    "# for neighborhood in df_listings['neighbourhood_cleansed'].unique():\n",
    "#     ads = get_neighborhood_adjectives(neighborhood)\n",
    "#     print(neighborhood, ':', ads[0])\n",
    "#     print(neighborhood, 'is:', ads[1].most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPsaep7TZ6-J"
   },
   "source": [
    "# Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oYM0cRdEZ9kv",
    "outputId": "8df86a07-27e3-481c-b7c4-8d5249739483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len total = 794377\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews_2020_03 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2020-03-16/data/reviews.csv.gz', compression='gzip')\n",
    "reviews_2019_18 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2019-10-18/data/reviews.csv.gz', compression='gzip')\n",
    "reviews_2018_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2018-10-11/data/reviews.csv.gz', compression='gzip')\n",
    "reviews_2017_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2017-10-06/data/reviews.csv.gz', compression='gzip')\n",
    "reviews_2016_09 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2016-09-07/data/reviews.csv.gz', compression='gzip')\n",
    "reviews_2015_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2015-10-03/data/reviews.csv.gz', compression='gzip')\n",
    "\n",
    "df_reviews = pd.concat([reviews_2020_03, reviews_2019_18, reviews_2018_10, reviews_2017_10, reviews_2016_09, reviews_2015_10])\n",
    "df_reviews['comments'] = df_reviews['comments'].astype(str)\n",
    "print('Len total =', len(df_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gvZp5O32cjrS"
   },
   "source": [
    "# Vibe Factor Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the neighborhood accuracy statistic for a listing\n",
    "# Neighborhood accuracy is the dot product between the neighborhood description\n",
    "# and the reviews left for the place. This metric is greatest when the experience\n",
    "# of the visitors most matched the vibe that was portrayed by the listing.\n",
    "\n",
    "# Neighborhood accuracy is calculated as the sum of the number of adjectives that appear \n",
    "# in both the neighborhood description and in the reviews for a listing,\n",
    "# weighted by the frequency by which those adjectives occur in all \n",
    "# neighborhood descriptions within that neighborhood.\n",
    "\n",
    "# calc_neighborhood_accuracy(comments_list) takes in a list of strings as the comments\n",
    "# for that listing. It returns a scalar neighborhood accuracy score.\n",
    "def calc_neighborhood_accuracy(comments_list):\n",
    "  neighborhood_accuracy = 0\n",
    "\n",
    "  listing_comments = re.sub('[^\\w\\s]+', '', ' '.join(comments_list)).split()\n",
    "  comment_freq = Counter(listing_comments)\n",
    "  comment_words = list(comment_freq.keys())\n",
    "\n",
    "  for i in range(len(adjectives)):\n",
    "    if (adjectives[i] in comment_words):\n",
    "      neighborhood_accuracy += frequencies[i] * comment_freq[adjectives[i]]\n",
    "\n",
    "  rating = df_listings.loc[df_listings['id'] == listing_id]['review_scores_rating']    \n",
    "  if len(rating) == 0:\n",
    "    print('listing id:', listing_id, 'rating:', rating)    \n",
    "  neighborhood_accuracy /= len(comments_list)\n",
    "\n",
    "  return neighborhood_accuracy\n",
    "\n",
    "# Calculates the mean sentiment of all reviews for a listing.\n",
    "def calc_happiness(comments_list):\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgh4KTu3cmO2"
   },
   "outputs": [],
   "source": [
    "def gen_data():\n",
    "  vibedict = []\n",
    "  for neighborhood in df_listings['neighbourhood_cleansed'].unique():\n",
    "\n",
    "    # Primary adjectives and their frequencies, used by all listings within to describe this neighborhood\n",
    "    neighborhood_adjectives = get_neighborhood_adjectives(neighborhood)[1]\n",
    "    adjectives = list(neighborhood_adjectives)\n",
    "    frequencies = [neighborhood_adjectives[adjective] for adjective in adjectives]\n",
    "\n",
    "    # for each listing within this neighborhood\n",
    "    for listing_id in df_listings.loc[df_listings['neighbourhood_cleansed'] == neighborhood]['id']:\n",
    "      \n",
    "      # List of comments for that listing\n",
    "      comments_list = df_reviews.loc[df_reviews['listing_id'] == listing_id]['comments'].tolist()\n",
    "      if len(comments_list) == 0:\n",
    "        continue\n",
    "\n",
    "      # Neighborhood accuracy metric (\"Consistency\")\n",
    "      consistency = calc_neighborhood_accuracy(comments_list)\n",
    "\n",
    "      # Average rating (\"Enjoyability\")\n",
    "      enjoyability = df_listings.loc[df_listings['id'] == listing_id]['review_scores_rating'].values[0]\n",
    "      \n",
    "      # Number of ratings (\"Popularity\")\n",
    "      popularity = len(comments_list)\n",
    "      \n",
    "      # Add this listing and its metrics to the dictionary\n",
    "      vibedict.append({'listing_id': listing_id,\n",
    "                       'lat': df_listings.loc[df_listings['id'] == listing_id]['latitude'].values[0],\n",
    "                       'lon': df_listings.loc[df_listings['id'] == listing_id]['longitude'].values[0],\n",
    "                       'enjoyability': enjoyability,\n",
    "                       'consistency': consistency,\n",
    "                       'popularity': popularity})\n",
    "\n",
    "  vibetable = pd.DataFrame(columns=['listing_id', 'lat', 'lon', 'enjoyability',  'consistency', 'popularity'])\n",
    "  vibetable = vibetable.append(vibedict, ignore_index=True)\n",
    "  return vibetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vibetable = gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "scaled_table = vibetable\n",
    "\n",
    "perception_accuracy = vibetable['consistency']\n",
    "perception_90 = np.quantile(perception_accuracy, .90)\n",
    "scaled_table['consistency'] = vibetable['consistency'].div(perception_90).clip(upper=1)\n",
    "\n",
    "num_reviews = vibetable['popularity']\n",
    "reviews_90 = np.quantile(num_reviews, .90)\n",
    "scaled_table['popularity'] = vibetable['popularity'].div(reviews_90).clip(upper=1)\n",
    "\n",
    "ratings = vibetable['enjoyability']\n",
    "ratings_90 = np.quantile(ratings, .90)\n",
    "scaled_table['enjoyability'] = np.log(vibetable['enjoyability'].div(ratings_90).clip(upper=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "wxbp2ItFQjkF",
    "outputId": "876463ff-21cc-4857-d677-82148648a8e6"
   },
   "outputs": [],
   "source": [
    "scaled_table.to_csv(\"dist/data/vibetable.csv\", index=False)\n",
    "scaled_table.to_json(\"dist/data/vibetable.json\", orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(scaled_table['rating'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.iloc[1]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings.loc[df_listings['id'] == 5506]['review_scores_rating'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "Airbnb Adjectives.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
