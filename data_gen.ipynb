{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21RGJj1IZ-4g"
   },
   "source": [
    "# Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "h6kf1rCRR2xK",
    "outputId": "9e55e8d0-603c-469d-d251-68224db07ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len total = 12480\n",
      "9684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        99.0\n",
       "1        95.0\n",
       "2        96.0\n",
       "3        93.0\n",
       "4        95.0\n",
       "        ...  \n",
       "2552     96.0\n",
       "2554     99.0\n",
       "2555     99.0\n",
       "2556    100.0\n",
       "2557     87.0\n",
       "Name: review_scores_rating, Length: 9684, dtype: float64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_2020_03 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2020-03-16/data/listings.csv.gz', compression='gzip')\n",
    "df_2019_18 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2019-10-18/data/listings.csv.gz', compression='gzip')\n",
    "df_2018_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2018-10-11/data/listings.csv.gz', compression='gzip')\n",
    "df_2017_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2017-10-06/data/listings.csv.gz', compression='gzip')\n",
    "df_2016_09 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2016-09-07/data/listings.csv.gz', compression='gzip')\n",
    "df_2015_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2015-10-03/data/listings.csv.gz', compression='gzip')\n",
    "\n",
    "df_original_listings = pd.concat([df_2020_03, df_2019_18, df_2018_10, df_2017_10, df_2016_09, df_2015_10]).drop_duplicates('id')\n",
    "# df_original_listings = pd.concat([df_2020_03, df_2019_18, df_2018_10, df_2017_10, df_2016_09]).drop_duplicates('id')\n",
    "# df_original_listings = pd.concat([df_2020_03, df_2019_18]).drop_duplicates('id')\n",
    "print('Len total =', len(df_original_listings))\n",
    "\n",
    "df_listings = df_original_listings.copy()\n",
    "df_listings = df_listings.replace('nan', '', regex=True)\n",
    "df_listings['summary'] = df_listings['summary'].astype(str)\n",
    "df_listings['space'] = df_listings['space'].astype(str)\n",
    "df_listings['description'] = df_listings['description'].astype(str)\n",
    "df_listings['neighborhood_overview'] = df_listings['neighborhood_overview'].astype(str)\n",
    "df_listings['host_neighbourhood'] = df_listings['host_neighbourhood'].astype(str)\n",
    "df_listings['neighbourhood_cleansed'] = df_listings['neighbourhood_cleansed'].astype(str)\n",
    "df_listings['notes'] = df_listings['notes'].astype(str)\n",
    "df_listings['review_scores_rating'] = df_listings['review_scores_rating'].astype(float)\n",
    "df_listings = df_listings[df_listings['review_scores_rating'].notna()]\n",
    "print(len(df_listings))\n",
    "df_listings['review_scores_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "H5ZijdxcR_fL",
    "outputId": "0f520d45-efa7-40b8-df7b-bee64d1776cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "# Download the natural language dataset for english, if this is the first run\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "# Load spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Add in common words that occurr in all listings, that really don't mean anything useful here\n",
    "nlp.Defaults.stop_words |= {'many', 'great', 'nearby', 'short', 'major', 'north', 'south', 'east', 'west', 'easy', 'true', 'local', 'public', 'mi', 'several', 'such', 'main', 'other'}\n",
    "\n",
    "# Creates a Counter of adjectives used in the \"neighborhood overview\" field of all listings\n",
    "# within the neighborhood name provided. \n",
    "def get_neighborhood_adjectives(name):\n",
    "  \n",
    "  # List of the \"neighborhood_overview\" field for all listings for this neighborhood\n",
    "  overviews = df_listings.loc[df_listings['neighbourhood_cleansed'] == name]['neighborhood_overview']\n",
    "  \n",
    "  list_overviews = '  '.join([overview for overview in overviews])\n",
    "    \n",
    "  # Combine all overviews into one, and load it into spacy\n",
    "  text = nlp(list_overviews)\n",
    "  \n",
    "  # Get the adjectives\n",
    "  adjectives = [token.lemma_ for token in text if token.pos_ == \"ADJ\" and not token.is_stop]\n",
    "  \n",
    "  # Count the adjectives\n",
    "  counter = Counter(adjectives)\n",
    "  \n",
    "  # Remove pronoun forms\n",
    "  counter.pop('-PRON-', None)\n",
    "  \n",
    "  return (len(overviews), counter)\n",
    "\n",
    "  \n",
    "# north_end = get_neighborhood_adjectives('North End')\n",
    "# print('Listings in north end:', north_end[0])\n",
    "# print('North end is:', north_end[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5pEcpPaSA73"
   },
   "outputs": [],
   "source": [
    "# for neighborhood in df_listings['neighbourhood_cleansed'].unique():\n",
    "#     ads = get_neighborhood_adjectives(neighborhood)\n",
    "#     print(neighborhood, ':', ads[0])\n",
    "#     print(neighborhood, 'is:', ads[1].most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPsaep7TZ6-J"
   },
   "source": [
    "# Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oYM0cRdEZ9kv",
    "outputId": "8df86a07-27e3-481c-b7c4-8d5249739483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len total = 154464\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews_2020_03 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2020-03-16/data/reviews.csv.gz', compression='gzip')\n",
    "# reviews_2019_18 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2019-10-18/data/reviews.csv.gz', compression='gzip')\n",
    "# reviews_2018_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2018-10-11/data/reviews.csv.gz', compression='gzip')\n",
    "# reviews_2017_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2017-10-06/data/reviews.csv.gz', compression='gzip')\n",
    "# reviews_2016_09 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2016-09-07/data/reviews.csv.gz', compression='gzip')\n",
    "# reviews_2015_10 = pd.read_csv('http://data.insideairbnb.com/united-states/ma/boston/2015-10-03/data/reviews.csv.gz', compression='gzip')\n",
    "\n",
    "df_reviews = pd.concat([reviews_2020_03])\n",
    "# df_reviews = pd.concat([reviews_2020_03, reviews_2019_18, reviews_2018_10, reviews_2017_10, reviews_2016_09, reviews_2015_10])\n",
    "df_reviews['comments'] = df_reviews['comments'].astype(str)\n",
    "print('Len total =', len(df_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gvZp5O32cjrS"
   },
   "source": [
    "# Vibe Factor Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculates the neighborhood accuracy statistic for a listing\n",
    "# Neighborhood accuracy is the dot product between the neighborhood description\n",
    "# and the reviews left for the place. This metric is greatest when the experience\n",
    "# of the visitors most matched the vibe that was portrayed by the listing.\n",
    "\n",
    "# Neighborhood accuracy is calculated as the sum of the number of adjectives that appear \n",
    "# in both the neighborhood description and in the reviews for a listing,\n",
    "# weighted by the frequency by which those adjectives occur in all \n",
    "# neighborhood descriptions within that neighborhood.\n",
    "\n",
    "# calc_neighborhood_accuracy(comments_list) takes in a list of strings as the comments\n",
    "# for that listing. It returns a scalar neighborhood accuracy score.\n",
    "def calc_neighborhood_accuracy(neighborhood_adjectives, neighborhood_frequencies, comments_list):\n",
    "  neighborhood_accuracy = 0\n",
    "\n",
    "  # Comments, excluding punctuation and special characters\n",
    "  listing_comments = re.sub('[^\\w\\s]+', '', ' '.join(comments_list)).split()\n",
    "  \n",
    "  # Count up the frequencies of these words\n",
    "  comment_freq = Counter(listing_comments)\n",
    "  comment_words = list(comment_freq.keys())\n",
    "\n",
    "  # Dot product time doo doo doo doo doo\n",
    "  for i in range(len(neighborhood_adjectives)):\n",
    "    if (neighborhood_adjectives[i] in comment_words):\n",
    "      neighborhood_accuracy += neighborhood_frequencies[i] * comment_freq[neighborhood_adjectives[i]]\n",
    "\n",
    "  neighborhood_accuracy /= len(comments_list)\n",
    "\n",
    "  return neighborhood_accuracy\n",
    "\n",
    "WALKABILITY_WORDS = [\"transit\", \"train\", \"subway\", \"T\", \"bus\", \"ride\", \"walk\", \"walking\", \"walkable\"]\n",
    "TRANQUILITY_WORDS = [\"quiet\", \"peace\", \"peaceful\", \"pleasant\", \"nice\"]\n",
    "\n",
    "# Calculates the mean sentiment of all reviews for a listing.\n",
    "def calc_happiness(comments_list):  \n",
    "  all_comments = '  '.join(comments_list)\n",
    "  \n",
    "  happiness = analyser.polarity_scores(all_comments)['compound']\n",
    "  return happiness\n",
    "  \n",
    "# Calculates the frequency of words within word list appearing in a comments list\n",
    "def calc_word_freq(comments_list, word_list):\n",
    "  total_count = 0\n",
    "  len_total = 0\n",
    "  \n",
    "  # Comments, excluding punctuation and special characters\n",
    "  listing_comments = re.sub('[^\\w\\s]+', '', ' '.join(comments_list)).split()\n",
    "\n",
    "  comment_freq = Counter(listing_comments)\n",
    "  comment_words = list(comment_freq.keys())\n",
    "\n",
    "  for word in comment_words:\n",
    "    len_total += comment_freq[word]\n",
    "    if word in word_list:\n",
    "      total_count += comment_freq[word]\n",
    "\n",
    "  # Normalized by total number of words\n",
    "  return total_count / len_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3164"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_happiness(['The movie sucked. That cake is the shit!'])\n",
    "# %timeit calc_word_freq(['I really enjoyed walking', 'Walkability is insane', 'Can walk anywhere you want'], [\"transit\", \"train\", \"subway\", \"T\", \"bus\", \"ride\", \"walk\", \"walking\", \"walkable\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgh4KTu3cmO2"
   },
   "outputs": [],
   "source": [
    "def gen_data():\n",
    "  vibedict = []\n",
    "  for neighborhood in df_listings['neighbourhood_cleansed'].unique():\n",
    "    \n",
    "    # Primary adjectives and their frequencies, used by all listings within to describe this neighborhood\n",
    "    neighborhood_adjectives = get_neighborhood_adjectives(neighborhood)[1]\n",
    "    adjectives = list(neighborhood_adjectives)\n",
    "    frequencies = [neighborhood_adjectives[adjective] for adjective in adjectives]\n",
    "\n",
    "    count = 1\n",
    "    listings = df_listings.loc[df_listings['neighbourhood_cleansed'] == neighborhood]['id']\n",
    "    total_num = len(listings)\n",
    "\n",
    "    print('Calculating vibes for', len(listings), 'listings in', neighborhood)\n",
    "\n",
    "    # for each listing within this neighborhood\n",
    "    for listing_id in listings:\n",
    "      \n",
    "      description = df_listings.loc[df_listings['id'] == listing_id]['description'].values[0]\n",
    "      n_overview = df_listings.loc[df_listings['id'] == listing_id]['neighborhood_overview'].values[0]\n",
    "            \n",
    "      # List of comments for that listing\n",
    "      comments_list = df_reviews.loc[df_reviews['listing_id'] == listing_id]['comments'].tolist()\n",
    "      num_comments = len(comments_list)\n",
    "      if num_comments == 0:\n",
    "        continue\n",
    "\n",
    "#       print('Vibe calculation for listing', listing_id, 'with', num_comments, 'comments')\n",
    "        \n",
    "      # Neighborhood accuracy metric (\"Honesty\")\n",
    "      honesty = calc_neighborhood_accuracy(adjectives, frequencies, comments_list)\n",
    "\n",
    "      # Average sentiment of reviews + Average rating (\"Happiness\")\n",
    "      happiness = df_listings.loc[df_listings['id'] == listing_id]['review_scores_rating'].values[0]\n",
    "#       + calc_happiness(comments_list)\n",
    "      \n",
    "      # Number of ratings (\"Liveliness\")\n",
    "      liveliness = len(comments_list)\n",
    "      \n",
    "      # Walkability + Transit, combined into one factor (\"Walkability\")\n",
    "      walkability = calc_word_freq(comments_list + [description, n_overview], WALKABILITY_WORDS)\n",
    "      \n",
    "      # Tranquility + Peacefulness, combined into one factor (\"Peacefulness\")\n",
    "      peacefulness = calc_word_freq(comments_list + [description, n_overview], TRANQUILITY_WORDS)\n",
    "      \n",
    "      # Add this listing and its metrics to the dictionary\n",
    "      vibedict.append({'listing_id': listing_id,\n",
    "                       'lat': df_listings.loc[df_listings['id'] == listing_id]['latitude'].values[0],\n",
    "                       'lon': df_listings.loc[df_listings['id'] == listing_id]['longitude'].values[0],\n",
    "                       'honesty': honesty,\n",
    "                       'happiness': happiness,\n",
    "                       'liveliness': liveliness,\n",
    "                       'walkability': walkability,\n",
    "                       'peacefulness': peacefulness})\n",
    "\n",
    "      count = count + 1\n",
    "\n",
    "  vibetable = pd.DataFrame(columns=['listing_id', 'lat', 'lon', 'honesty',  'happiness', 'liveliness', 'walkability', 'peacefulness'])\n",
    "  vibetable = vibetable.append(vibedict, ignore_index=True)\n",
    "  return vibetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating vibes for 567 listings in East Boston\n",
      "Calculating vibes for 534 listings in Roxbury\n",
      "Calculating vibes for 631 listings in Downtown\n",
      "Calculating vibes for 758 listings in Back Bay\n",
      "Calculating vibes for 894 listings in Dorchester\n",
      "Calculating vibes for 720 listings in South End\n",
      "Calculating vibes for 347 listings in North End\n",
      "Calculating vibes for 299 listings in Charlestown\n",
      "Calculating vibes for 735 listings in Jamaica Plain\n",
      "Calculating vibes for 717 listings in Allston\n",
      "Calculating vibes for 483 listings in South Boston\n",
      "Calculating vibes for 96 listings in Bay Village\n",
      "Calculating vibes for 572 listings in Brighton\n",
      "Calculating vibes for 109 listings in West Roxbury\n",
      "Calculating vibes for 165 listings in Roslindale\n",
      "Calculating vibes for 471 listings in Beacon Hill\n",
      "Calculating vibes for 273 listings in Mission Hill\n",
      "Calculating vibes for 160 listings in South Boston Waterfront\n",
      "Calculating vibes for 595 listings in Fenway\n",
      "Calculating vibes for 156 listings in West End\n",
      "Calculating vibes for 193 listings in Chinatown\n",
      "Calculating vibes for 86 listings in Mattapan\n",
      "Calculating vibes for 86 listings in Hyde Park\n",
      "Calculating vibes for 16 listings in Leather District\n",
      "Calculating vibes for 21 listings in Longwood Medical Area\n"
     ]
    }
   ],
   "source": [
    "vibetable = gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "scaled_table = vibetable.copy()\n",
    "\n",
    "scaled_table['honesty'] = (vibetable['honesty'] - np.quantile(vibetable['honesty'], 0.01)).clip(lower=0)\n",
    "scaled_table['honesty'] = (scaled_table['honesty'] / np.quantile(scaled_table['honesty'], 0.99)).clip(upper=1)\n",
    "\n",
    "scaled_table['happiness'] = (vibetable['happiness'] - np.quantile(vibetable['happiness'], 0.01)).clip(lower=0)\n",
    "scaled_table['happiness'] = (scaled_table['happiness'] / np.quantile(scaled_table['happiness'], 0.99)).clip(upper=1)\n",
    "\n",
    "scaled_table['liveliness'] = (vibetable['liveliness'] - np.quantile(vibetable['liveliness'], 0.0000001)).clip(lower=0)\n",
    "scaled_table['liveliness'] = (scaled_table['liveliness'] / np.quantile(scaled_table['liveliness'], 0.99)).clip(upper=1)\n",
    "\n",
    "scaled_table['walkability'] = (vibetable['walkability'] - np.quantile(vibetable['walkability'], 0.01)).clip(lower=0)\n",
    "scaled_table['walkability'] = (scaled_table['walkability'] / np.quantile(scaled_table['walkability'], 0.985)).clip(upper=1)\n",
    "\n",
    "scaled_table['peacefulness'] = (vibetable['peacefulness'] - np.quantile(vibetable['peacefulness'], 0.01)).clip(lower=0)\n",
    "scaled_table['peacefulness'] = (scaled_table['peacefulness'] / np.quantile(scaled_table['peacefulness'], 0.99)).clip(upper=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "wxbp2ItFQjkF",
    "outputId": "876463ff-21cc-4857-d677-82148648a8e6"
   },
   "outputs": [],
   "source": [
    "scaled_table.to_json(\"dist/data/scaled_table.json\", orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 53.,   0.,   0.,   0.,   0.,   1.,   1.,   2.,   5.,   0.,   2.,\n",
       "          1.,  16.,   1.,   0.,   1.,  12.,   2.,   3.,   0.,   9.,   6.,\n",
       "          7.,   3.,   0., 103.,  11.,  14.,  28.,   0.,  25.,  29.,  34.,\n",
       "         63.,  70.,   0.,  64., 162., 102.,   0., 124., 176., 161., 182.,\n",
       "          0., 259., 246., 257., 204., 553.]),\n",
       " array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ,\n",
       "        0.22, 0.24, 0.26, 0.28, 0.3 , 0.32, 0.34, 0.36, 0.38, 0.4 , 0.42,\n",
       "        0.44, 0.46, 0.48, 0.5 , 0.52, 0.54, 0.56, 0.58, 0.6 , 0.62, 0.64,\n",
       "        0.66, 0.68, 0.7 , 0.72, 0.74, 0.76, 0.78, 0.8 , 0.82, 0.84, 0.86,\n",
       "        0.88, 0.9 , 0.92, 0.94, 0.96, 0.98, 1.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(scaled_table['happiness'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading in already calculated happiness data\n",
    "\n",
    "# import pandas as pd\n",
    "# happiness = pd.read_json('dist/data/vibetable.json', orient='index')['happiness']\n",
    "\n",
    "# scaled_table['happiness'] = (happiness - np.quantile(happiness, 0.01)).clip(lower=0).replace(1, 0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>...</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>is_business_travel_ready</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, listing_url, scrape_id, last_scraped, name, summary, space, description, experiences_offered, neighborhood_overview, notes, transit, access, interaction, house_rules, thumbnail_url, medium_url, picture_url, xl_picture_url, host_id, host_url, host_name, host_since, host_location, host_about, host_response_time, host_response_rate, host_acceptance_rate, host_is_superhost, host_thumbnail_url, host_picture_url, host_neighbourhood, host_listings_count, host_total_listings_count, host_verifications, host_has_profile_pic, host_identity_verified, street, neighbourhood, neighbourhood_cleansed, neighbourhood_group_cleansed, city, state, zipcode, market, smart_location, country_code, country, latitude, longitude, is_location_exact, property_type, room_type, accommodates, bathrooms, bedrooms, beds, bed_type, amenities, square_feet, price, weekly_price, monthly_price, security_deposit, cleaning_fee, guests_included, extra_people, minimum_nights, maximum_nights, minimum_minimum_nights, maximum_minimum_nights, minimum_maximum_nights, maximum_maximum_nights, minimum_nights_avg_ntm, maximum_nights_avg_ntm, calendar_updated, has_availability, availability_30, availability_60, availability_90, availability_365, calendar_last_scraped, number_of_reviews, number_of_reviews_ltm, first_review, last_review, review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value, requires_license, license, jurisdiction_names, instant_bookable, is_business_travel_ready, cancellation_policy, require_guest_profile_picture, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 106 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_listings.loc[df_listings['id'] == 1651]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "Airbnb Adjectives.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:vibe-of-boston] *",
   "language": "python",
   "name": "conda-env-vibe-of-boston-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
